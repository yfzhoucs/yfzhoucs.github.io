---
permalink: /
title: # "Academic Pages is a ready-to-fork GitHub Pages template for academic personal websites"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

Hello! I’m Yifan Zhou, currently a PhD student at Interactive Robotics Lab at Arizona State University, supervised by [Prof. Heni Ben Amor](http://henibenamor.weebly.com/). My primary research interests lie in **Robot Learning** and **Large Models**. My publications are shown at **CoRL**, **COLM**, **IROS**, **ICRA**, etc. In my PhD research, I majorly focus on 2 topics:

**(1)** Study of data-efficient imitation learning methods for language-conditioned robot manipulation, by either improving transformer models, or harnessing foundation models for higher data quality.

**(2)** Leveraging (V)LLMs as a guidance for embodied robot behavior, with the insight that (V)LLMs are capable of providing critiques for robots or maneuvering robot actions for better styles.

\[ [Publications](publications/) \]  \[ [CV](files/Yifan Zhou 5.7.pdf) \]


Work Experience
------
<p style="margin-bottom: 0;"><b>Google LLC</b></p>
<p style="margin-top: 0; margin-bottom: 0;">Software Engineering Intern</p>
<p style="margin-top: 0; margin-bottom: 0;"><i>Summer 2024</i></p>
<ul style="margin-top: 0">
  <li style="margin-top: 0; margin-bottom: 0;">Proposed and implemented a holistic data quality assurance mechanism for the SFT data of a series of LLMs, for the product <strong>Gemini for Google Workspace</strong>.</li>
  <li style="margin-top: 0; margin-bottom: 0;">The proposed mechanism includes 3 parts: rule-based checkers, LLM-based checkers and AutoEval-based checkers, which identify data format issues (e.g., missing critical fields), semantic issues (e.g., the mismatch between model final response and user query), and overall quality issues (e.g., the overall impression of the final response) respectively.</li>
  <li style="margin-top: 0">The implemented checkers detected problems up to <strong>20.1%</strong> of the training datapoints. This helps the data curation team to improve the data quality, and in turn helps the training of Gemini for Google Workspace LLMs.</li>
</ul>

<p style="margin-bottom: 0;"><b>LinkedIn Corporation</b></p>
<p style="margin-top: 0; margin-bottom: 0;">Machine Learning – Artificial Intelligence Engineering Intern</p>
<p style="margin-top: 0; margin-bottom: 0;"><i>Summer 2020</i></p>
<ul style="margin-top: 0">
  <li style="margin-top: 0; margin-bottom: 0;">Created a <strong>BERT</strong> based LinkedIn member profile modeling approach, namely EntityBERT.</li>
  <li style="margin-top: 0; margin-bottom: 0;">Proposed 2 objectives for the training of EntityBERT: masked-entity-modeling and profile-relation-prediction.</li>
  <li style="margin-top: 0; margin-bottom: 0;">The trained model was able to predict missing fields of given LinkedIn user profiles, where the top 1 accuracy was increased by over <strong>10%</strong> compared to previous baselines.</li>
  <li style="margin-top: 0">EntityBERT provides the team with a user profile modeling methodology and creates an entity recommendation approach for downstream teams.</li>
</ul>

Education
------
**Arizona State University**\
Ph.D. in Computer Science\
*2021 - Present*

**Carnegie Mellon University**\
M.S. in Artificial Intelligence and Innovation\
*2019 - 2021*

**Southwest Jiaotong University**\
B.E. in Computer Science and Technology\
*2015 - 2019*

